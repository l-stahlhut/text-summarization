{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6388,"status":"ok","timestamp":1650964729752,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"i_YzL-i2o0H0","outputId":"bdb37b17-0c0d-4054-fd9c-cd27d0356260"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.0.0)\n"]}],"source":["!pip install transformers datasets\n","!pip3 install rouge_score"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4079,"status":"ok","timestamp":1650964733823,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"gz3YgKT4l4UK","outputId":"70530c54-e1b1-4dca-9fbb-a58de5def0cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from tqdm import tqdm\n","import re\n","import transformers\n","import nltk\n","nltk.download('punkt')\n","from sklearn.model_selection import train_test_split\n","\n","from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer, DataCollatorForSeq2Seq, BigBirdPegasusPreTrainedModel\n","import datasets\n","from datasets import load_dataset, list_metrics, load_metric\n","from datasets import Features, Sequence, Value\n","from transformers import TrainingArguments, Trainer, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from torch.utils.checkpoint import checkpoint"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":54,"status":"ok","timestamp":1650964733829,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"ekPwSs-Zq4ll"},"outputs":[],"source":["EPOCH = 4\n","MODEL_VERSION = 2\n","TRAIN = True\n","TRAIN_PATH = '/content/drive/MyDrive/Text-Mining/Data/sentence_selection/train_with_shortened_sent_sel_3072.tsv'\n","TEST_PATH = '/content/drive/MyDrive/Text-Mining/Data/sentence_selection/test_with_shortened_sent_sel_3072.tsv'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":16294,"status":"ok","timestamp":1650964750080,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"o-Wud8PP8H8z","outputId":"6f86b70a-b07b-44d2-9b22-c0598518d102"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     id                                         highlights  \\\n","4595  S0377221715003239  Anticipation is different in the open-loop com...   \n","2028  S0167839613000502  Two special syzygies for complex rational curv...   \n","2052  S0167839614000211  Explicit Representations of three μ-basis elem...   \n","8292  S1568494614000052  A decentralized machine learning method that d...   \n","1304  S0020019014001744  A unified framework is proposed for mutual exc...   \n","...                 ...                                                ...   \n","5436  S0885230814001211  We propose three different types of curriculum...   \n","898   S0010482514002042  Coupled bioheat and blood flow model has been ...   \n","2960  S0262885614001012  We present the first 3D dynamic spontaneous fa...   \n","4119  S0377221714005876  We propose a robust revenue management model w...   \n","4315  S0377221714009023  Decentralized optimization of energy and delay...   \n","\n","                                     shortened_articles  \n","4595  We find that under an open-loop information st...  \n","2028  We present a fast algorithm for finding a μ-ba...  \n","2052  We provide explicit representations of three m...  \n","8292  It is thus demonstrated that the proposed lear...  \n","1304  Mutual exclusion is a fundamental process sync...  \n","...                                                 ...  \n","5436  This paper addresses the issue of language mod...  \n","898   Graphical abstract specific heat (Jkg−1 K−1)\\n...  \n","2960  Most publically available databases are limite...  \n","4119  While the criterion is defined on a myriad of ...  \n","4315  With a queueing network model, @xcite study th...  \n","\n","[8112 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-4a7e1762-02ed-4ba5-a398-d5f9b1d81029\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>highlights</th>\n","      <th>shortened_articles</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4595</th>\n","      <td>S0377221715003239</td>\n","      <td>Anticipation is different in the open-loop com...</td>\n","      <td>We find that under an open-loop information st...</td>\n","    </tr>\n","    <tr>\n","      <th>2028</th>\n","      <td>S0167839613000502</td>\n","      <td>Two special syzygies for complex rational curv...</td>\n","      <td>We present a fast algorithm for finding a μ-ba...</td>\n","    </tr>\n","    <tr>\n","      <th>2052</th>\n","      <td>S0167839614000211</td>\n","      <td>Explicit Representations of three μ-basis elem...</td>\n","      <td>We provide explicit representations of three m...</td>\n","    </tr>\n","    <tr>\n","      <th>8292</th>\n","      <td>S1568494614000052</td>\n","      <td>A decentralized machine learning method that d...</td>\n","      <td>It is thus demonstrated that the proposed lear...</td>\n","    </tr>\n","    <tr>\n","      <th>1304</th>\n","      <td>S0020019014001744</td>\n","      <td>A unified framework is proposed for mutual exc...</td>\n","      <td>Mutual exclusion is a fundamental process sync...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5436</th>\n","      <td>S0885230814001211</td>\n","      <td>We propose three different types of curriculum...</td>\n","      <td>This paper addresses the issue of language mod...</td>\n","    </tr>\n","    <tr>\n","      <th>898</th>\n","      <td>S0010482514002042</td>\n","      <td>Coupled bioheat and blood flow model has been ...</td>\n","      <td>Graphical abstract specific heat (Jkg−1 K−1)\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>2960</th>\n","      <td>S0262885614001012</td>\n","      <td>We present the first 3D dynamic spontaneous fa...</td>\n","      <td>Most publically available databases are limite...</td>\n","    </tr>\n","    <tr>\n","      <th>4119</th>\n","      <td>S0377221714005876</td>\n","      <td>We propose a robust revenue management model w...</td>\n","      <td>While the criterion is defined on a myriad of ...</td>\n","    </tr>\n","    <tr>\n","      <th>4315</th>\n","      <td>S0377221714009023</td>\n","      <td>Decentralized optimization of energy and delay...</td>\n","      <td>With a queueing network model, @xcite study th...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8112 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a7e1762-02ed-4ba5-a398-d5f9b1d81029')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4a7e1762-02ed-4ba5-a398-d5f9b1d81029 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4a7e1762-02ed-4ba5-a398-d5f9b1d81029');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["train_df = pd.read_csv(TRAIN_PATH, sep='\\t', usecols=[2, 6, 12])\n","test_df = pd.read_csv(TEST_PATH, sep='\\t', usecols=[2, 6, 12])\n","\n","\n","train_df, val_df = train_test_split(train_df.dropna(), test_size=0.2)\n","\n","train_df.to_csv('clean_train.tsv', sep='\\t', index=False)\n","val_df.to_csv('clean_val.tsv', sep='\\t', index=False)\n","test_df.dropna().to_csv('clean_test.tsv', sep='\\t', index=False)\n","\n","train_df"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650964750081,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"SHEkMKoCMadH"},"outputs":[],"source":["features = Features({'id': Value('string'), \n","                     'highlights': Value('string'), \n","                     'shortened_articles': Value('string')})"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167,"referenced_widgets":["49b81775e9fc4b63a538b3c3274bac78","6ba13617ca564934a7923e66ca8319b3","01a759d6c8084c408ae46eca7487f3f2","4f91b11ebf5044868ca2a14bf753a65e","22f0706cc7d54a4da63d983df775f758","ed1fa885fc9b45a598b8324c58e05d74","51bc15c55a664770a311f70b21462aa0","d152d2a0aed8434f9ccbea1aafb8542c","877ba2ec9dfd4cada31479a66683edb7","09b0d3be5d064327a7180ec46b1dcacf","2415438244d14a299af0e0e861946a5a","7ff166bbdafd4984b6d0626dc8aff21e","b5078161ff8e4b248177a7fec67119e0","6cfd582289a848deb709304f954774b5","35b5533754bd405f834b7daa95cd63df","d42dcb3471e2420583dd268f9eab6125","bf9ce2d993f44684865488136d67d778","e6ec23811f6b431487d07fc432d8fc24","ca8c6d86afcf40f4acd166252a917e74","c47278819d974cbba0d7a165c35edb8d","59ebf53b9d894b118adfd17dacfb5e0c","cec8200ca21e44e4a94db82fd81dd8dc","9551f657007c4cf38a13a409fb0bfdcb","dd828be2e087447db013d56e36e8646f","64738c76461f49d59fe78743fea4a034","6dfc59654c544f1c92cd7603337ddd3a","5e8eca5a86294071983e3ee566cbf593","93928807a5c74b3481eaba72eda610fc","fc7e72e56a524028901d783c0bf95867","c398a33cf1ec40cba8b690e86e6d4558","c48c812656584962a7c97352941aaa9a","4caf583d20af415a9ca8e9e0bf0a2f12","a384c795423e48c6b33c91e8efe44e15"]},"executionInfo":{"elapsed":1085,"status":"ok","timestamp":1650964751160,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"1cQuULVlF66r","outputId":"94e43f0c-55a7-4e95-83f7-816cb2f68310"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration default-b357e8fa7ac76c91\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-b357e8fa7ac76c91/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49b81775e9fc4b63a538b3c3274bac78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ff166bbdafd4984b6d0626dc8aff21e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-b357e8fa7ac76c91/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9551f657007c4cf38a13a409fb0bfdcb"}},"metadata":{}}],"source":["dataset = load_dataset('csv', \n","                       data_files={'val': 'clean_val.tsv', 'test': 'clean_test.tsv'}, \n","                       delimiter='\\t',\n","                       features=features)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3594,"status":"ok","timestamp":1650964754740,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"lTniY4Ibkl5A"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7463,"status":"ok","timestamp":1650964762190,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"9HzAB4o4rx_g"},"outputs":[],"source":["model_for_eval = BigBirdPegasusForConditionalGeneration.from_pretrained(\n","    f\"/content/drive/MyDrive/Text-Mining/model_v{MODEL_VERSION}/epoch{EPOCH}\", \n","    attention_type=\"block_sparse\",\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1650964762195,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"},"user_tz":-120},"id":"0cxdXdzHsdSW"},"outputs":[],"source":["full_text = dataset['val']['shortened_articles']"]},{"cell_type":"code","source":["all_preds = []\n","\n","for text in tqdm(full_text[:150]):\n","    input = tokenizer(text, padding=True, truncation=True, max_length=3072, return_tensors='pt')\n","    prediction_ids = model_for_eval.generate(\n","        **input, \n","        #attention_mask=input_ids['attention_mask'], \n","        repetition_penalty=1.3,\n","        min_length=50,\n","        do_sample=True, \n","        max_length=100, \n","        top_k=20, \n","        top_p=0.95,\n","        temperature=0.8\n","    )\n","\n","    all_preds.append(prediction_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":481},"id":"eu56GmReBzUn","executionInfo":{"status":"error","timestamp":1650966650715,"user_tz":-120,"elapsed":1888548,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"}},"outputId":"ee79a44e-a9f8-4917-c02a-b99a45afbcfa"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/150 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:805: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  * num_indices_to_pick_from\n"," 13%|█▎        | 20/150 [13:41<1:27:55, 40.58s/it]Attention type 'block_sparse' is not possible if sequence_length: 161 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"," 29%|██▊       | 43/150 [31:28<1:18:18, 43.91s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-f0090260f9a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m             )\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_sample\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2477\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2478\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2479\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2480\u001b[0m             )\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2558\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m         )\n\u001b[1;32m   2562\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2440\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m         )\n\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2294\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2296\u001b[0;31m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2297\u001b[0m                 )\n\u001b[1;32m   2298\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m   1546\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1549\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["tokenizer.decode(all_preds[18][0], skip_special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"HE9gaEI845RU","executionInfo":{"status":"ok","timestamp":1650966727565,"user_tz":-120,"elapsed":319,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"}},"outputId":"2f11c633-3f54-4367-8956-b7b01aa2b477"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'a new approach to the construction of piecewise polynomial spaces is presented.<n> it is based on the idea that each element of the space can be represented by a polynomial function.<n> the coefficients of such functions are analyzed.<n> the method is applied to the case of piecewise polynomial spaces generated by knot-spline.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["all_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltcKkBaDR_NL","executionInfo":{"status":"ok","timestamp":1650966662150,"user_tz":-120,"elapsed":357,"user":{"displayName":"Deborah Jakobi","userId":"17125812085449662997"}},"outputId":"a7da0041-a18e-4c9a-8606-f113d73b961f"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[   2,  109,  486,  113,  109, 1474,  752,  407,  140, 5221,  115,  109,\n","           908,  135, 5851,  112, 2191,  110,  107,  333,  136,  908,  110,  108,\n","           109,  344,  113,  910, 1519,  140, 1222,  221,  991,  110,  107,  106,\n","           109, 1077,  564,  113,  910, 1519,  140, 1222,  221,  991,  110,  107,\n","           106,  109, 1077, 8605,  564,  113,  910, 1519,  140, 1222,  221,  991,\n","           130,  210,  110,  107,    1]]),\n"," tensor([[    2,   145, 10287,   114,   501,   725,  7680,   143, 19765,   586,\n","          17758,  1356,   110,   158,   120, 12990,   116,   109,  4421,   725,\n","           5661,   113,   391,  4803, 12036,   725,   111,  1122,  4803, 12036,\n","            725,   110,   107,   109,  1356,   117,   451,   124,   391,  4803,\n","          12036,   725,   111,  1122,  4803, 12036,   725,   110,   107,   106,\n","            109,   637,   117,  1711,   464, 11779,  2489,   110,   107,     1]]),\n"," tensor([[    2,   136,   800, 12414,   109,   637,   113,   114,   405,   603,\n","            327,   173,   109,  4728,   117,   146,  4032,   122,   109,   348,\n","            113,   109,   405,   110,   107,   106,   145,  1037,   228,  1020,\n","            113,  3049,   549,   110,   107,   115,   109,   211,   619,   110,\n","            108,   106,   109,  4728,   117, 30920,   122,   109,   348,   113,\n","            109,   405,   110,   107,   115,   109,   453,   619,   110,   108,\n","            106,   109,  4728,   117,  4032,   122,   109,   348,   113,   109,\n","            405,   155,   358,   146,   697,   115,   109,  1443,  1289, 11661,\n","          51228, 14508, 40692, 36349,  7499, 72409,   902, 24530, 84539,  8140,\n","          61600, 24900,  4594, 66617, 71736, 77187, 67537, 38195, 55333, 20888]]),\n"," tensor([[    2,   136,   800,  3702,   142,  7680,   118,  6676,   114,   612,\n","           1157,  8235,   575,   113,  2119,  4052,   166,   160,   114,   830,\n","            640,   796,   110,   107,   106,   109,  2962,  7680,   592,  5520,\n","            945,   118,   164,   112,  4789,  1665,   110,   107,   110,   106,\n","            587,   107, 42843,  3957, 21970,   177, 12473,   599,   599,   696,\n","            497,   599, 13162,   540,   497, 13162, 13162,   540,   497, 13162,\n","            599,   540,   497,   686, 12473,   280,   323,  1803, 25099,  3957,\n","          66554,     1]]),\n"," tensor([[    2,   136,   201,   117,   451,   124,   142, 53744,  1014,   124,\n","          13248, 10526,   110,   107,   106,   136,  1014,   117,   451,   124,\n","            109,  1893,   113, 21407, 14711,   110,   107,   106,   109,  1893,\n","            113, 21407, 14711,   117,   451,   124,   109,  1893,   113, 21407,\n","           2115,   110,   107,   106,   109,  1893,   113, 21407, 14711,   117,\n","            451,   124,   109,  1893,   113, 21407,  2115,   110,   107,     1]]),\n"," tensor([[    2,   114,   177,  7680,   117,  2962,   118,   109,   117, 58858,\n","          30121,  1382,   113,  8696,  3808,   110,   107,   106,   109,  7680,\n","            117,   451,   124,   109,   641,   120,   109, 13754,   113,   109,\n","           8696,  3808,   137,   129,  3035,   141,   109,  7680,   110,   107,\n","            106,   109,   641,   117,   120,   109,   117, 58858, 30121,  1382,\n","            137,   129,  2303,   122,   209,   109, 13754,   113,   109,  8696,\n","           3808,   270, 17480, 61995,   110,   107,     1]]),\n"," tensor([[    2,   136,   800, 12414,   109,  1521,   113,   303,   291,  8591,\n","            112,  4783,   109,   348,   113,   114,  5256,   861,   110,   107,\n","            106,   109,  8026,   195,  2303,   303,   109,   428,  1116, 22072,\n","            110,   107,   106,   109,   602,   403,   120,   303,   291,  8591,\n","            137,   927,   109,   348,   113,   114,  5256,   861,   110,   107,\n","              1]]),\n"," tensor([[    2,   145,   207, 52796,  1625,   112,  1735,   109,   344,   113,\n","          17428, 11418,   116,   656,   115,   385,   112,  6976,   109,  1077,\n","           1407,   166,   110,   107,   106,   145,   403,   602,   124,   109,\n","            637,   113,   109,   920,   121, 78606,  7680,   110,   108,   162,\n","            117,   993,   118,  3137,   113,   109,  7680,   115,   846,   110,\n","            107,     1]]),\n"," tensor([[    2,   145, 10287,   114,  2794,  5640,   327,   118,  2037, 10497,\n","          29064,   451,   124,   612, 41812,  1055,   110,   107,   106,   109,\n","           2962,   327,  3471,   113,   228,   972,   110,   107,   106,   109,\n","            211,   297,   117,   114,  4088,   121,   936,  1048,  9463,  1356,\n","            110,   107,   106,   109,   453,   297,   117,   114,   569,  7680,\n","            110,   107,   106,   109,   569,  7680,   117,   451,   124,   109,\n","            207,   113,  4817,   121, 24574,  4830,  8826,  5652,   110,   107,\n","              1]]),\n"," tensor([[    2,   136,   800,  3702,   114, 13584,  3772,   118,  1546,   121,\n","          30990, 29064,   141,  8177,   111,  5125,   273,   276,  2005,   303,\n","            188, 11547,  8495,   111,  4836,   861,  5384,  9714,   130,  2489,\n","            113,  5347,   135,  1331,  5541,   110,   107,   106,   114,   970,\n","            437,   173,   109, 11547,   317,   142,  2951,   111,   203,  2518,\n","           1494,   117, 36024,   117,  1848,   110,   107,     1]]),\n"," tensor([[    2,   136,   800,  3702,   142,  3938, 13475, 29064,  1356,   118,\n","          46368,  9537,  3002,  1055,   110,   107,   106,   109,   637,   113,\n","            302,  2143,   121,   936,   111,  1322,   121,   936,  8970,   195,\n","          10920,   303,   114,   121, 12269,  1803, 21524,  9840,  3884,  1298,\n","            110,   107,   106,  1322,   121,   936, 13475,   140,   374,   112,\n","            133,   203,   282,  4373,   111, 19143,   118, 21997,  9537, 29064,\n","            110,   107,   106,   701,  1184, 13475,  7680,   122,  2143, 27987,\n","            140,  5994,   112,   129,   957,   115,  5125,   273,  1079,  1482,\n","           1674, 53457, 66755, 83169, 22631, 69363, 84902, 17502, 70514, 16969,\n","          58236, 37004,  2122,  3953,  7224, 62215, 78474, 61102, 29102,  3937]]),\n"," tensor([[    2,   136,   800,  3702,  5242,  1047,   118,   562, 12648,   113,\n","          20348,   121,  1139, 21407,   562,   747,   365, 26963,  1660,  1784,\n","            110,   107,   114,   177,   660,   113, 21453,  5728,  1014,   117,\n","           1184,   112,  2690,   109, 55957,  1746,   113,   302,   582,   121,\n","           1139, 46621, 21407, 49991,  2489,   111,   109,  1546, 52919,   113,\n","          21407,  2489,   190,   181, 19765, 50631,   110,   107,   114,   711,\n","            110,   108,   162, 27695,   116,   109, 45063,   113, 21407,  6481,\n","            365,   952,  4285,   110,   107,     1]]),\n"," tensor([[    2,   136,   800, 19390,   114,  1607,  6506,  1356,   451,   124,\n","          27441,   813,   121, 82442, 14849,   952,   143,  2962,   110,   158,\n","            110,   107,   106,   109,  1557,   113,   109,  2962,  1607,  6506,\n","           1356,   117,   813,   121, 30533,   110,   107,   106,   109, 26394,\n","            113,   109,  2962,  1607,  6506,  1356,   117,  3552,   115,   302,\n","            109,   813,   121, 82442,  3181,   111,   109,  3181,   645,   109,\n","          10193,   113,   109,  1557,   110,   107,     1]]),\n"," tensor([[    2,   114,  2794, 20460,  1546,   121, 72636,  7002,  7680,   117,\n","            237,  2962,   110,   108,   162,   839,  1648,   113,   142,  1387,\n","            121,  4668,  6812,   391,   725,  1520,   118,  1546,   121, 72636,\n","           7002,   112,   927,   109, 18579,   113,   109,  7680,   110,   107,\n","            106,   109,  2962,  7680,   117,  8905,   124,  1202,  6636,   110,\n","            107,     1]]),\n"," tensor([[    2,   145,  1037,   109,   575,   113,  1663,   142,  5520,   951,\n","            112,   114,  7162,  2080,   575,   120,   117,  3302,   122,   149,\n","            121, 19337, 28861, 18425,   116,   111,   449,  5520,  2922,  1047,\n","            110,   107,   106,   145,   403,   199,   112,  3607,   149,   121,\n","          19337, 28861, 18425,   116,   122,  4762,  2233,   115,   253,   114,\n","            230,   120,   142,  5520,   951,   137,   129,   374,   110,   107,\n","              1]]),\n"," tensor([[    2,   136,   800, 19390,   114,  1122, 20068,   562,  1356,   224,\n","          41037,  7002,   122,   114,  1122, 27987,   120,  2120,   114, 20068,\n","           2516,   124,   109,   664,  1557,   132,  2672,   121, 23802,   116,\n","            110,   107, 17327,  2724,   127,  1848,   112,  4454,   120,   109,\n","           2962,  1356,   117,  3159,   113,  2448,  1663,  5520,   945,   118,\n","           5961, 10626,   110,   107,     1]]),\n"," tensor([[    2,   109,   674,  1396,   113,   136,   800,   117,   112,  3193,\n","            109,  3376,  1402,   575,   110,   107,   106,   145,  1037,   109,\n","            861,   130,   114,   664, 25604,   339,   121, 72636,  7002,   575,\n","            110,   107,   106,   145,   736,  5520,   945,   118,   109,  3376,\n","           1402,   575,   141,  1456,  2467,   495,   110,   107,   106,   145,\n","           1037,   109,   861,   130,   114,   664, 25604,   339,   121, 72636,\n","           7002,   575,   110,   107,     1]]),\n"," tensor([[    2,   145, 10287,   114,  9791,   451,  3772,   118,  1546, 23955,\n","           1383,  1382,   110,   107,   106,   109,  3772, 40701,   116,   146,\n","            209,   109,  9252,  5114,   113,   580,   476,  2575,   121,  7115,\n","           8484,   155,   163,  2250,  2074,   317,   183,   110,   107,   106,\n","            109,  3772,   117,  2140,   112,  2418,   545,  1382,   110,   107,\n","              1]]),\n"," tensor([[    2,   114,   177,  1014,   112,   109,  1187,   113,  1038, 10301,\n","          63100,  2849,   117,  1848,   110,   107,   106,   126,   117,   451,\n","            124,   109,   641,   120,   276,  3160,   113,   109,   501,   137,\n","            129,  4543,   141,   114, 63100,  1434,   110,   107,   106,   109,\n","          47312,   113,   253,  2489,   127, 10082,   110,   107,   106,   109,\n","           1356,   117,  2140,   112,   109,   437,   113,  1038, 10301, 63100,\n","           2849,  3943,   141, 14031,   121, 12269,  1803,   110,   107,     1]]),\n"," tensor([[    2,   136,   800,  3702, 14831, 26061,  1057,   476, 11741,   111,\n","           2135,   476, 11741,   118,   109,   229,  2613, 13267,   113,  6219,\n","          27192, 10918,   110,   107,   110,   106, 14831, 26061,  1057,   476,\n","          11741,   111,  2135,   476, 11741,   118,   109,   229,  2613, 13267,\n","            113,  6219, 27192, 10918,  1384,   757, 46819,   117,  1848,   107,\n","              1]]),\n"," tensor([[    2,  2119, 44238,  8970,   193, 48088,   257,  4400,   115,   109,\n","            335,   323,   160, 14427,  5198,   107,  1681,   121,   936, 44238,\n","           8970,   193, 48088,   257,  4400,   115,   109,   335,   323,   160,\n","          14427,  5198,   107,   136,  7680,  3702,   114,   586,   277,  1882,\n","           7680,   107, 10461,  1663,   391,  6923,  2634,   118,   276,   491,\n","           1187,   113, 48088,   116,   107,     1]]),\n"," tensor([[    2,   136,   800,  3702,   114,  2794,  6985,   118,  1612,  4505,\n","            113,   335,   204,  3873,  3296,   110,   107,   106,   109,   750,\n","            113,   109,  2962,  6985,   117,   451,   124,   109,  5652,   113,\n","            609,   233,  4657,   113,   142, 89627,  3752,   110,   107,   106,\n","            109,  2962,  6985,   137,   129,   263,   115,   114, 24500,   849,\n","            110,   107,   110,   106,  2834,  6921,   110,   151,  2834,  1612,\n","           4505,   113,   335,   204,  3873,  3296,   110,   108,   750,   113,\n","            335,   110,   108,   952,   257,   111,   203,  1971,     1]]),\n"," tensor([[    2,   145, 10287,   114, 47868,  2569,   112,  4324,   109,   861,\n","           5384,   110,   107,   106,   109,  2569,   117, 17788,   303,   339,\n","            291,   335,   121, 22124,   110,   151,   888,  1068,   111,   613,\n","            121,  1704, 11042,   110,   107,   110,   106, 18976,  4708, 16480,\n","            214,   135,   109,   861,   110,   107,   110,   106, 47868,  2569,\n","            112,  4324,   109,   861,  5384,   110,   107,     1]]),\n"," tensor([[    2,   109,   428, 19215,  3267,   575,   117, 10592,   141,  1682,\n","            601,  8437,   110,   107,   106, 47868,   951,   115,   428, 19215,\n","          14059,   117, 10592,   141,  8437,   141, 47868,   951,   113,  1482,\n","            121,  5129,  3044,   121, 19337, 28861, 47868,  7002,   575,   117,\n","            263,   115,  3957,   107,  3957,   107,  3957,   107,  3957,   107,\n","           3957,   107,  3957,   107,  3957,   107,  3957,   107,  3957,   107,\n","           3957,   107,  3957,   107,  3957,   107,  3957,   107,  3957,     1]]),\n"," tensor([[    2,   145,   248,   728,   339,   291,  4362,   451,   124,   580,\n","            121,   111,   609, 34324,   490, 23185,  2749,   110,   206,   145,\n","           7938,  1746,   120,  1137,   118,   580,   121,   111,   609, 34324,\n","            490, 23185,  2749,   110,   206,   145,   319,   993,  1047,   124,\n","           2477,   113, 30637,   165, 32042,  1625,  2140,   115, 35022, 14284,\n","            743,   110,   107,     1]]),\n"," tensor([[    2, 45663,  3683,   117,  2962,   112,  3193,  6022,  4817, 40513,\n","          43214,   743,   110,   107,   106,   109,  1356,   117,   451,   124,\n","            114,  5195, 20348, 21261,  7680,   110,   107,   106,   109,  1356,\n","            117,   451,   124,   228,   662,   675,   110,   107,   106,   211,\n","            110,   108,   142, 20460,  7680,   117,  2962,   110,   107,   106,\n","            453,   110,   108,   142, 18976,  7680,   117,  2962,   110,   107,\n","            106,   109,  1356,   117,   451,   124,   228,   662,   675,   110,\n","            107,   106,   211,   110,   108,   142, 14009,  3804,  1412, 56866,\n","          24457, 10221, 41393, 83413, 27180, 29787, 10492, 78481, 34510, 16376,\n","          44164,  9223, 69826, 54858, 80007, 80318, 40091, 75194, 71234, 44189]]),\n"," tensor([[    2,   136,   800,  5002,   114,  2933,  3772,   113,  4918,   440,\n","           1139,  1160,   120,   319,   114,   210,   121, 11111,   637,   118,\n","            580,  6506,   121, 10322,   111,   142,  3137,   130,   210,   130,\n","            203,   229,   121, 11111,   637,   107,   109,  3772,   117,  5924,\n","            113,   228,   972,   110,   151,   723,   121, 12948,   111,   723,\n","            121, 12948,   972,   110,   107,     1]]),\n"," tensor([[    2,   145, 10287,   110, 55214,  6254,   120,   117,  5076,   464,\n","           3543,   110,   107,   106,   109,  1356,   117,   451,   124,   109,\n","            645,   675,   110,   107,   106,   211,   110,   108,   145,   207,\n","            449,   121,  1384,   757, 23811,  3142,   111,   449,   121,  1384,\n","            757, 23811,   740,   110,   107,   106,   453,   110,   108,   145,\n","            207,   860, 24378,   121,  1384,   757, 23811,   522,   111,   860,\n","          24378,   121,  1384,   757, 23811,   726,   110,   107,   106,   776,\n","            110,   108,   145,  4291,  2672,   121,   107,   326,  5484, 15634,\n","          14397, 87209, 16613, 48417,  1051, 72388, 60979, 23951, 49208, 77694,\n","          48890, 55957, 11398, 43298,  7998, 14657, 23273, 15980, 73476, 66729]]),\n"," tensor([[    2,   354,   113, 11844,   233,  5571,  3296,   117,   114,  2782,\n","            575,   110,   107,   106,   136,   800, 19390,   114,  1356,   118,\n","            354,   113, 11844,   233,  5571,  3296,   110,   107,   106,   354,\n","            113, 11844,   233,  5571,  3296,   117,   114,  2782,   575,   110,\n","            107,   106,   136,   800, 19390,   114,  1356,   118,   354,   113,\n","          11844,   233,  5571,  3296,   110,   107,     1]]),\n"," tensor([[    2,  1937, 16627,   115,  3845,   562,   117,  4525,   110,   107,\n","            106,   109,  1356,   117,   451,   124,   142, 14831,   952,   110,\n","            107,   106,   126,   117,  1673,   120,   136,  1356,   137,  4324,\n","           2900,  3062,   254,   173,   181,  1937,   117,  4504,   110,   107,\n","            106,   109,  1356,   117,  2140,   112,   114,  2127,  5568,   327,\n","            110,   107,     1]]),\n"," tensor([[    2,   692,   140,  3047,   112,  5731,   109,  1298,   113,  4090,\n","           1090,   124,  6667,  1959,   637,   115,   142,  3727,   327,   110,\n","            107,   106,  5083,   140,  3047,   303,   114,   958,   327,   110,\n","            107,   106,   602,  4298,   120,  1273,   127,  5387,   173,   186,\n","            117, 23659,   113,  1250,  1090,   190,   109,   637,   113,   142,\n","           3727,   327,   110,   107,     1]]),\n"," tensor([[    2,   425,   778, 12788,   133,   174,  1673,   112,  2541,   883,\n","            426,   111,   927,  7439,   113,   425,   379,   110,   107,   115,\n","            136,   692,   145,  3199,   109,  7864, 95899,   113,  4958,   778,\n","          12788,   143,  2880,   110, 17787, 44474,  2880,   439,   208, 15100,\n","           4191,   110,   108,   149,   551, 43933,  1108, 72118,   158,   111,\n","            153,  4526,   710,  1613,   143,   336,   111,  2479,   110,   158,\n","            110,   107,   602,   403,   120,  4958,   778, 12788, 15356,   340,\n","            197,   153,  4526,  3737,  1613,   110,   151,  4658,  1196,  1686,\n","          91416, 81656, 63652, 67009, 16155, 70777, 92095, 25307, 59093, 10856,\n","          16578, 11066, 43620, 10464, 74813, 58985, 93676, 43065, 61771, 68294]]),\n"," tensor([[    2,   114,   861,   113,  2977,  2725,   117,  1184,   120,  7127,\n","          11279,   109,  1746,   113,   142,  5964,  2249,  2575,   115,   114,\n","           1907,  1961,   110,   107,   106, 34859,  1407,   113,  1907,  1961,\n","            117, 13130,   303,  3044, 21109,  3160,  1014,   110,   107,   106,\n","          17327, 18486,  4298,  4426,  4456,   113,  2962,   339,   121,  3483,\n","          15997,   110,   107,     1]]),\n"," tensor([[   2, 7093,  110,  151,  354,  113,  114, 1546, 3275, 2075, 2922,  327,\n","           117,  142, 3727,  354,  575,  110,  107,  106,  354,  113,  114, 1546,\n","          3275, 2075, 2922,  327,  117,  142, 3727,  354,  575,  110,  107,  106,\n","           354,  113,  114, 1546, 3275, 2075, 2922,  327,  117,  142, 3727,  354,\n","           575,  107,    1]]),\n"," tensor([[    2,   109,   575,   117,   120,   109,   916,  3508, 10422, 12182,\n","            116,   365,  1780,   231,   110,   107,   106,   109,   951,   117,\n","          83128,  3035,   110,   107,   106,   109,   945,   127, 73615, 10082,\n","            110,   107,   106,   109,   945,   127,  1848,   115,   114,   826,\n","            110,   107,   106,  1877,  1877,  6921,   110,   151,  1062, 10422,\n","            110,   108,   916,  3508, 10422,   110,   108, 31718,   861,   110,\n","            108, 10174,   951,     1]]),\n"," tensor([[    2,  1581,   118,  6506,   580,   121, 30782, 23280,  2574,   137,\n","           2512,   280, 21109,  1811,   162,   127, 73615,  6529,   280,   107,\n","           1581,   118,  6506,   580,   121, 30782, 23280,  2574,   137,  2512,\n","            280, 21109,  1811,   162,   127, 73615,  6529,   280,   107,  1581,\n","            118,  6506,   580,   121, 30782, 23280,  2574,   137,  2512,   280,\n","          21109,  1811,   162,   127, 73615,  6529,   280,   107,     1]]),\n"," tensor([[    2,   136,   800,  2194,   122,   109,   575,   113,  1122, 90429,\n","           4528,   113,  2543,   121,  4668,  9359,   121,  8544,  1016,  5899,\n","            365,   623,  8160,   113, 39783,  3884,   111, 17198, 38084,  7398,\n","            110,   107,   112,   136,   370,   110,   108,   142,  7680,   117,\n","           1848,   120,  1481,  2004, 39783,  3884,  2295,   113, 39783, 13288,\n","            111,  2004,   344,  2885,  1431,   344,  1014,   110,   107,     1]]),\n"," tensor([[    2, 65108,  2119,  2638,  1062,  3471,   113,   109,   645,  2274,\n","            110,   151,   143,   532,   110,   158,   114,  1976,   113, 25866,\n","            116,   110,   108,   143, 27333,   110,   158,   114,  1976,   113,\n","          10765,  5899,   110,   108,   143, 51318,   110,   158,   114,  1976,\n","            113, 42322,  5899,   110,   108,   143, 53301,   110,   158,   114,\n","           1976,   113,   609, 73435,  5899,   110,   108,   143,  2294,   110,\n","            158,   114,  1976,   113,   609, 73435,  5899,   110,   108,   143,\n","          18604,   110,   158,   142,  5520, 32130,   120,  4083, 11949, 10863,\n","          50766,  4163, 21145, 93031, 61017, 87763, 13090, 19875, 70704, 68658,\n","          41708, 39651, 80038, 91697, 88666,  9419, 64533, 22367, 94111, 41599]]),\n"," tensor([[    2, 64897, 29512,   113, 47868, 15299,   575,   117,  1184,   124,\n","            613,   713,   113,   166,   143,  1143,  4116,   111,  7135, 24065,\n","            110,   158,   110,   107,   106, 52796,   116,   127,   263,   112,\n","           3193,   114,   323,   113, 34505,  6636,   115,   613,   713,   113,\n","            166,   110,   107,   106,   602,   403,   120,   150,  1356,   117,\n","           5076,   110,   107,     1]]),\n"," tensor([[    2,   136,   800,  3972,   124,  2598, 75372,  8890,   121,   111,\n","           7746,   121, 29064,   111,  6247,   115,   958, 23440,  5220,   143,\n","            958, 23440,  5220,   110,   158,   110,   107,   106,   114,  6136,\n","          82808, 25722,  1494,   861,   117,  2962,   118,   296, 45959,  1711,\n","            569,  1348,   111,  2951,   121,  7115, 29064,   117,  2962,   303,\n","          11926,  1431,   556,   111,  6136, 82808, 25722,  2143,   121,  6254,\n","            117,  2492,   303, 11926,  1431,   556,   111,  6136, 82808, 25722,\n","           1494, 15767,   110,   107,   112,  3199,   122, 51723,   971, 10238,\n","           2499, 55719, 25836, 91299,  7614, 71503, 26517, 41730, 37757, 88591,\n","          46791, 24076, 13886, 17125, 27035, 59836, 40118, 21505,  6319, 46742]]),\n"," tensor([[    2,   324,  1683,  1753, 13183,   111,  4324,   819,  6014,   707,\n","            141,   303,   335,   124,   819,  6056,  2764,   132,   141, 25364,\n","            135,   335,  2650,   757, 46819,   107,   324,   909,  1683,  1753,\n","          13183,   111,  4324,   819,  6014,   707,   141,   303,   335,   124,\n","            819,  6056,  2764,   132,   141, 25364,   135,   335,  2650,   757,\n","          46819,   107,   201,   117, 13679,   112,   219,  3392,   110,   107,\n","              1]]),\n"," tensor([[    2,   145,  1037,   114,   956,  1374,   113,   114,  1038, 10301,\n","          77507, 52281, 22667,   431,   120,   117,  3213,   291,  2340,   124,\n","            109,   327,  2212,   124,   181,  1047,   111,  3486,   120,   148,\n","            174,  4440,   115,   110, 42438, 39319,  1431, 77507,  2672,  3393,\n","            116,   110,   107,   106,   109,   800,   117,  7314,   130,  4083,\n","            110,   107,   106,   211,   110,   108,   145,   799,   109,   956,\n","           1014,   110,   107,   106,   453,   110,   108,   145,   403,   109,\n","           1298,   113,   109,  3137,   110,   108,   145,   403,   114,  1147,\n","           1660, 63601, 40567, 58017, 87251, 47964, 65054, 57588, 27916, 76807,\n","          91386, 79470, 74951, 94282, 91676, 40158, 14781, 38701, 22993, 81756]]),\n"," tensor([[    2,   109,  1298,   113,   580,  1972,   111,   580,  1367,   124,\n","           8466,   115,   911,   261,  1467, 31253,  4829,  8368,   140,  4525,\n","            110,   107,   106,   109,  1298,   113,   580,  1972,   111,   580,\n","           1367,   124,  8466,   115,   911,   261,  1467, 31253,  4829,  8368,\n","            140,  9789,   110,   107,   106,   109,  1298,   113,   580,  1972,\n","            111,   580,  1367,   124,  8466,   115,   911,   261,  1467, 31253,\n","           4829,  8368,   140,  9789,   110,   107,     1]])]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"IZmawmXESAcN"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"experiments_with_generate_function.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1PX_9AwaMNOMDmh2IgWw_3V_MTgifPsUV","authorship_tag":"ABX9TyPXuh2/M6nXIhiJlBPkN2bs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"49b81775e9fc4b63a538b3c3274bac78":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ba13617ca564934a7923e66ca8319b3","IPY_MODEL_01a759d6c8084c408ae46eca7487f3f2","IPY_MODEL_4f91b11ebf5044868ca2a14bf753a65e"],"layout":"IPY_MODEL_22f0706cc7d54a4da63d983df775f758"}},"6ba13617ca564934a7923e66ca8319b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed1fa885fc9b45a598b8324c58e05d74","placeholder":"​","style":"IPY_MODEL_51bc15c55a664770a311f70b21462aa0","value":"Downloading data files: 100%"}},"01a759d6c8084c408ae46eca7487f3f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d152d2a0aed8434f9ccbea1aafb8542c","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_877ba2ec9dfd4cada31479a66683edb7","value":2}},"4f91b11ebf5044868ca2a14bf753a65e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09b0d3be5d064327a7180ec46b1dcacf","placeholder":"​","style":"IPY_MODEL_2415438244d14a299af0e0e861946a5a","value":" 2/2 [00:00&lt;00:00, 74.77it/s]"}},"22f0706cc7d54a4da63d983df775f758":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed1fa885fc9b45a598b8324c58e05d74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51bc15c55a664770a311f70b21462aa0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d152d2a0aed8434f9ccbea1aafb8542c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"877ba2ec9dfd4cada31479a66683edb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09b0d3be5d064327a7180ec46b1dcacf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2415438244d14a299af0e0e861946a5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ff166bbdafd4984b6d0626dc8aff21e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5078161ff8e4b248177a7fec67119e0","IPY_MODEL_6cfd582289a848deb709304f954774b5","IPY_MODEL_35b5533754bd405f834b7daa95cd63df"],"layout":"IPY_MODEL_d42dcb3471e2420583dd268f9eab6125"}},"b5078161ff8e4b248177a7fec67119e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf9ce2d993f44684865488136d67d778","placeholder":"​","style":"IPY_MODEL_e6ec23811f6b431487d07fc432d8fc24","value":"Extracting data files: 100%"}},"6cfd582289a848deb709304f954774b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca8c6d86afcf40f4acd166252a917e74","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c47278819d974cbba0d7a165c35edb8d","value":2}},"35b5533754bd405f834b7daa95cd63df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59ebf53b9d894b118adfd17dacfb5e0c","placeholder":"​","style":"IPY_MODEL_cec8200ca21e44e4a94db82fd81dd8dc","value":" 2/2 [00:00&lt;00:00, 52.15it/s]"}},"d42dcb3471e2420583dd268f9eab6125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf9ce2d993f44684865488136d67d778":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6ec23811f6b431487d07fc432d8fc24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca8c6d86afcf40f4acd166252a917e74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c47278819d974cbba0d7a165c35edb8d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59ebf53b9d894b118adfd17dacfb5e0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cec8200ca21e44e4a94db82fd81dd8dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9551f657007c4cf38a13a409fb0bfdcb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd828be2e087447db013d56e36e8646f","IPY_MODEL_64738c76461f49d59fe78743fea4a034","IPY_MODEL_6dfc59654c544f1c92cd7603337ddd3a"],"layout":"IPY_MODEL_5e8eca5a86294071983e3ee566cbf593"}},"dd828be2e087447db013d56e36e8646f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93928807a5c74b3481eaba72eda610fc","placeholder":"​","style":"IPY_MODEL_fc7e72e56a524028901d783c0bf95867","value":"100%"}},"64738c76461f49d59fe78743fea4a034":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c398a33cf1ec40cba8b690e86e6d4558","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c48c812656584962a7c97352941aaa9a","value":2}},"6dfc59654c544f1c92cd7603337ddd3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4caf583d20af415a9ca8e9e0bf0a2f12","placeholder":"​","style":"IPY_MODEL_a384c795423e48c6b33c91e8efe44e15","value":" 2/2 [00:00&lt;00:00, 69.90it/s]"}},"5e8eca5a86294071983e3ee566cbf593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93928807a5c74b3481eaba72eda610fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc7e72e56a524028901d783c0bf95867":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c398a33cf1ec40cba8b690e86e6d4558":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c48c812656584962a7c97352941aaa9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4caf583d20af415a9ca8e9e0bf0a2f12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a384c795423e48c6b33c91e8efe44e15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}